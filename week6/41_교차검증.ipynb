{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "- 여러 단계(전처리, 변환, 추정)를 연속적으로 연결하여 실행하는 도구\n",
    "- 전처리와 모델을 하나의 객체로 결합해서 사용이 가능\n",
    "- 교차검증, 하이퍼 파라미터 탐색에서 유용 사용\n",
    "- 데이터의 누수를 방지 : fit_transform()이 학습데이터에만 적용이 되도록 자동 관리\n",
    "\n",
    "- 매개변수\n",
    "    - steps\n",
    "        - 필수 항목 (dict 형태의 데이터 타입)\n",
    "        - 파이프라인의 단계들을 커스텀한 이름과 객체들을 쌍으로 묶어서 dict 형태로 구성\n",
    "        - 예. [ ( 'scaler', StandardScaler()), ( 'svc', SVC() ) ]\n",
    "    - verbose\n",
    "        - 기본값: False\n",
    "        - 각 단계가 실행이 될 때 로그를 출력할 것인가?\n",
    "- 속성\n",
    "    - named_steps\n",
    "        - 파이프라인의 각 단계를 딕셔너리형처럼 접근이 가능\n",
    "        - 예. pipe.named_steps['svc']\n",
    "\n",
    "- 메서드\n",
    "    - fit(x, y, fit_params)\n",
    "        - 순서대로 각 단계의 fit을 진행\n",
    "        - 마지막 단계는 예측이 가능한 모델이어야한다.\n",
    "    - fit_transform(x, y, fit_params)\n",
    "        - 순서대로 각 단계의 fit_transform()을 진행\n",
    "        - 마지막 단계가 변환을 시켜주는 클래스\n",
    "    - predict(x)\n",
    "        - 마지막 단계에서 predict 함수를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "iris = pd.read_csv(\"../data_git/data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(iris['target'].unique()):\n",
    "    print(i)\n",
    "    print(key)\n",
    "    iris['target'] = iris['target'].replace(key, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop('target', axis=1)\n",
    "y = iris['target']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인을 생성 -> StdScaler를 이용, SVC() 모델을 사용\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('Scaler', StandardScaler()),\n",
    "        ('svc', SVC()),\n",
    "    ],\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pipe = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.93      0.88      0.90        16\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 보고서 출력\n",
    "print(classification_report(pred_pipe, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "- 하이퍼파라미터(매개변수) 조합을 탐색하여 최적의 조합을 찾는 방법\n",
    "- 각 파라미터 조합별로 교차검증(CV)을 수행해 평균 성능 비교\n",
    "- 최적의 모델과 성능을 자동으로 제공\n",
    "\n",
    "- 매개변수\n",
    "    - estimator\n",
    "        - 모델의 선택\n",
    "        - 예. SVC()\n",
    "    -param_grid\n",
    "        - 탐색할 파라미터의 조합\n",
    "        - 예. {'C' : [0, 1, 10], 'kernel' : ['linear', 'rbf']}\n",
    "    - cv\n",
    "        - 교차 검증의 횟수\n",
    "        - 5 -> 5-폴드 교차 검증\n",
    "    - scoring\n",
    "        - 기본값 : None\n",
    "        - 평가 지표 설정\n",
    "        - 기존에 제공하는 평가 지표와 커스텀하여 생성한 평가 지표도 사용 가능\n",
    "    - refit\n",
    "        - 기본값: True\n",
    "        - 최적의 파라미터로 전체 데이터를 다시 학습할 것인가\n",
    "        - True인 경우에는 속성 중 best_estimator_ 사용 가능\n",
    "    - error_score\n",
    "        - 기본값: np.nan\n",
    "        - 모델 학습 시 오류가 발생했을 때 어떤 방식으로 처리할 것인가?\n",
    "        - \"raise\" -> 에러 발생/숫자 -> 해당 스코어를 발생하는 숫자로 표시\n",
    "    - return_train_score\n",
    "        - 기본값: False\n",
    "        - 교차검증 시 훈련 성능 점수까지 반영을 할 것인가?\n",
    "    - verbose\n",
    "        - 기본값 : 0\n",
    "        - 출력 로그의 수준 (0: 없음, 1: 간단하게 표시, 2: 상세하게 표시)\n",
    "    - n_jobs\n",
    "        - 기본값: None\n",
    "        - cpu 병렬 처리 개수\n",
    "        - -1 : 모든 코어를 사용\n",
    "- 속성\n",
    "    - cv_results\n",
    "        - 각 파라미터 조합 별 성능 결과 (훈련/검증 점수, fit 시간)\n",
    "    - best_estimator_\n",
    "        - 최적의 파라미터로 다시 학습이 된 모델 객체\n",
    "    - best_params_\n",
    "        - 최적의 성능을 낸 파라미터 조합\n",
    "    - best_score_\n",
    "        - 최적의 파라미터 조합을 이용한 교차 검증에서의 평균 성능 점수\n",
    "    - refit_time_\n",
    "        - 최적의 파라미터로 refit을 하는데 걸린 시간\n",
    "- 메서드\n",
    "    - fit(x, y)\n",
    "        - 모든 파라미터 조합에 대해 학습하고 평가 -> 최적의 모델을 학습\n",
    "    - predict(x)\n",
    "        - 최적의 모델을 이용해 예측\n",
    "    - predict_proba(x)\n",
    "        - 분류인 경우에 확률 예측\n",
    "    - score(x, y)\n",
    "        - 최적의 모델로 점수를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "최적의 파라미터 조합 :  {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "최고의 score :  0.9800000000000001\n",
      "최적의 분류 모델 :  SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# 독립변수 x, 종속변수 y 그대로 이용\n",
    "# 파라미터 탐색에서 사용할 모델을 생성\n",
    "svc = SVC()\n",
    "\n",
    "# 최적의 파라미터를 찾기 위한 파라미터 조합\n",
    "param_grid = {\n",
    "    'C' : [0.1, 1, 10],\n",
    "    'kernel' : ['linear', 'rbf'],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# SVC가 분류모델이니까 -> 평가 지표 -> accuracy\n",
    "# 교차 검증의 횟수는 5회\n",
    "grid = GridSearchCV(\n",
    "    estimator=svc, \n",
    "    param_grid = param_grid,\n",
    "    cv = 5, \n",
    "    scoring = 'accuracy',\n",
    "    verbose = 1,\n",
    "    refit = True\n",
    ")\n",
    "# 학습을 돌려서 최적의 파라미터를 구성한다.\n",
    "grid.fit(x, y)\n",
    "\n",
    "# 최적의 파라미터 조합들을 확인\n",
    "print(\"최적의 파라미터 조합 : \", grid.best_params_)\n",
    "print(\"최고의 score : \", grid.best_score_)\n",
    "print(\"최적의 분류 모델 : \", grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
